import torch
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from tqdm import tqdm

from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset

# from torchvision import transforms
from torchvision.datasets import ImageFolder

from mvtec_dataset import MVTecDataset

# Albumentations ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import albumentations as A
from albumentations.pytorch import ToTensorV2

from anomalib.models import Patchcore
from anomalib.engine import Engine
from anomalib.data import ImageBatch
from torchmetrics.classification import BinaryConfusionMatrix

# ì¶”ê°€ ë°ì´í„°ì…‹ ë¡œë”©ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤ëŠ” ì—¬ì „íˆ ìœ íš¨í•©ë‹ˆë‹¤.
class AnomalibDatasetWrapper(Dataset):
    def __init__(self, dataset_to_wrap):
        self.dataset_to_wrap = dataset_to_wrap

    def __len__(self):
        return len(self.dataset_to_wrap)

    def __getitem__(self, idx):
        image, _ = self.dataset_to_wrap[idx]
        # Engineì´ fit/testì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        # DataLoaderê°€ ìë™ìœ¼ë¡œ í…ì„œë¡œ ë¬¶ì–´ì¤ë‹ˆë‹¤.
        return {"image": image, "label": 0}


# ë”•ì…”ë„ˆë¦¬ë¥¼ ImageBatch ê°ì²´ë¡œ ë³€í™˜í•´ì£¼ëŠ” 'ë²ˆì—­ê¸°' í•¨ìˆ˜
def custom_collate_fn(batch):
    """
    DataLoaderê°€ ìƒì„±í•œ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ anomalibì˜ ImageBatch ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    # batchëŠ” [{'image': tensor, 'label': 0, 'image_path': '...'}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    images = torch.stack([item['image'] for item in batch])
    labels = torch.tensor([item['label'] for item in batch])
    masks = torch.stack([item['mask'] for item in batch])
    image_paths = [item['image_path'] for item in batch]
    # 'gt_mask' í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ImageBatchì— ë§ˆìŠ¤í¬ ì „ë‹¬
    return ImageBatch(image=images, gt_label=labels, gt_mask=masks, image_path=image_paths)


def plot_confusion_matrix(tn, fp, fn, tp, save_path):
    conf_matrix = np.array([[tn, fp], [fn, tp]])
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Predicted Normal', 'Predicted Anomaly'],
                yticklabels=['Actual Normal', 'Actual Anomaly'])
    plt.title('Confusion Matrix')
    plt.ylabel('Actual Label')
    plt.xlabel('Predicted Label')
    plt.savefig(save_path)
    print(f"\nğŸ“Š Confusion Matrix ê·¸ë˜í”„ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    # --- 1. ì„¤ì • ---
    ROOT_DIR_MVTEC = 'C:/Users/AI-00/Desktop/mvtec_anomaly_detection'
    CATEGORY = 'capsule'
    IMAGE_SIZE = 256
    BATCH_SIZE = 32
    PROJECT_ROOT = Path("./anomalib_results")
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # --- 2. ë°ì´í„° ì¤€ë¹„ ---
    print("Loading datasets with masks...")
    # torchvision.transforms.Compose ëŒ€ì‹  A.Composeë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    transform_pipeline = A.Compose([
        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, always_apply=True),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ])

    # MVTecDatasetì€ albumentations ë³€í™˜ê¸°ë¥¼ ì „ë‹¬ë°›ìŒ
    train_dataset = MVTecDataset(root_dir=ROOT_DIR_MVTEC, category=CATEGORY, phase='train',
                                 transform=transform_pipeline)
    full_test_dataset = MVTecDataset(root_dir=ROOT_DIR_MVTEC, category=CATEGORY, phase='test',
                                     transform=transform_pipeline)

    val_size = int(0.5 * len(full_test_dataset))
    test_size = len(full_test_dataset) - val_size
    val_dataset, test_dataset = random_split(full_test_dataset, [val_size, test_size])

    print(f"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}")

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,
                              collate_fn=custom_collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,
                            collate_fn=custom_collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,
                             collate_fn=custom_collate_fn)

    # --- 3. ëª¨ë¸ ë° ì—”ì§„ ì´ˆê¸°í™” ---
    print("\nInitializing PatchCore model and Engine...")
    model = Patchcore()
    engine = Engine(default_root_dir=PROJECT_ROOT, accelerator=device, devices=1)
    print("Model and Engine initialized.")

    # --- 4. ëª¨ë¸ í•™ìŠµ ---
    print(f"\n--- Training PatchCore for '{CATEGORY}' category ---")
    engine.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)
    print("--- Training complete ---")

    # --- 5. ì„±ëŠ¥ í‰ê°€ ---
    print("\n--- Testing on original MVTec test set ---")
    # datamodule ëŒ€ì‹  test_loaderë¥¼ ì§ì ‘ ì „ë‹¬í•©ë‹ˆë‹¤.
    test_results = engine.test(model=model, dataloaders=test_loader)
    print("--- Testing and Visualization complete ---")

    # --- 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
    results_dict = test_results[0]
    print("\n--- Predicting to get raw labels for Confusion Matrix ---")
    # datamodule ëŒ€ì‹  test_loaderë¥¼ ì§ì ‘ ì „ë‹¬í•©ë‹ˆë‹¤.
    predictions = engine.predict(model=model, dataloaders=test_loader)

    all_pred_labels = []
    all_gt_labels = []
    all_gt_masks = []
    for batch in predictions:
        all_pred_labels.append(batch.pred_label)
        all_gt_labels.append(batch.gt_label)
        all_gt_masks.append(batch.gt_mask)  # ë§ˆìŠ¤í¬ ê²°ê³¼ ìˆ˜ì§‘
    predicted_labels = torch.cat(all_pred_labels)
    ground_truth_labels = torch.cat(all_gt_labels)

    bcm = BinaryConfusionMatrix().to(device)
    conf_mat_tensor = bcm(predicted_labels.to(device), ground_truth_labels.to(device))
    tn, fp, fn, tp = conf_mat_tensor.flatten().int().tolist()
    print("--- Confusion Matrix calculation complete ---")

    total_normal_test = (ground_truth_labels == 0).sum().item()
    total_abnormal_test = (ground_truth_labels == 1).sum().item()

    print("\n" + "=" * 50)
    print("ìµœì¢… ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼")

    # --- 7. ì˜¤íƒì§€/ë¯¸íƒì§€ ì´ë¯¸ì§€ ë¶„ì„ ---
    # test_dataset (Subset ê°ì²´)ì—ì„œ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    print("\n" + "=" * 50)
    print("ì˜¤íƒì§€ ë° ë¯¸íƒì§€ ìƒì„¸ ë¶„ì„")
    print("=" * 50)
    test_image_paths = [test_dataset.dataset.image_paths[i] for i in test_dataset.indices]

    fp_indices = torch.where((ground_truth_labels.cpu() == 0) & (predicted_labels.cpu() == 1))[0]
    fn_indices = torch.where((ground_truth_labels.cpu() == 1) & (predicted_labels.cpu() == 0))[0]
    print(f"\n[ì˜¤íƒì§€ëœ ì •ìƒ ì´ë¯¸ì§€ (False Positives) - ì´ {len(fp_indices)}ê°œ]")
    if len(fp_indices) > 0:
        for idx in fp_indices:
            print(f"  - {Path(test_image_paths[idx]).name}")
    else:
        print("  - ì—†ìŒ")
    print(f"\n[ë¯¸íƒì§€ëœ ë¶ˆëŸ‰ ì´ë¯¸ì§€ (False Negatives) - ì´ {len(fn_indices)}ê°œ]")
    if len(fn_indices) > 0:
        for idx in fn_indices:
            print(f"  - {Path(test_image_paths[idx]).name}")
    else:
        print("  - ì—†ìŒ")

    figure_save_path = Path(engine.trainer.log_dir)
    image_save_path = figure_save_path / "images"
    print("\n[ë¶„ì„ ë°©ë²•]")
    print("ìœ„ ì´ë¯¸ì§€ ì´ë¦„ê³¼ ë™ì¼í•œ íˆíŠ¸ë§µì„ ì•„ë˜ ê²½ë¡œì—ì„œ ì°¾ì•„ ì›ì¸ì„ ë¶„ì„í•˜ì„¸ìš”:")
    print(f"â¡ï¸  {image_save_path.resolve()}")
    print("=" * 50)

if __name__ == '__main__':
    main()